{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principle : Naive Bayes classifiers are a family of classifiers that are quite similar to the linear models discussed in the previous section. However, they tend to be even faster in training. The price paid for this efficiency is that naive Bayes models often provide generalization performance that is slightly worse than that of linear classifiers like LogisticRegression and LinearSVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from utils import feature_selection\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.33\n",
      "Test set accuracy: 0.34\n",
      "Test set accuracy: 0.34\n",
      "Test set accuracy: 0.40\n",
      "Test set accuracy: 0.46\n",
      "Test set accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "gt = pd.read_csv('../dumps/2020.01.13-14.25.csv')\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data = gt[cols]\n",
    "target = gt['label']\n",
    "\n",
    "values = [0.1,0.2,0.4,0.6,0.8,0.9]\n",
    "\n",
    "for i in values:\n",
    "    data_train, data_test, target_train, target_test = train_test_split(data,target, test_size = i, random_state = 0)\n",
    "\n",
    "    gnb = GaussianNB()\n",
    "\n",
    "    gnb.fit(data_train, target_train)\n",
    "    print(\"Test set accuracy: {:.2f}\".format(gnb.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, no matter of big the test size is, the performances with the Gaussian classifier are really bad for this dataset. Let's try with more samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.13\n",
      "Test set accuracy: 0.17\n",
      "Test set accuracy: 0.21\n",
      "Test set accuracy: 0.24\n",
      "Test set accuracy: 0.32\n",
      "Test set accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "gt = pd.read_csv('../dumps/2020.02.10-12.14.csv')\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data = gt[cols]\n",
    "target = gt['label']\n",
    "\n",
    "values = [0.1,0.2,0.4,0.6,0.8,0.9]\n",
    "\n",
    "for i in values:\n",
    "    data_train, data_test, target_train, target_test = train_test_split(data,target, test_size = i, random_state = 0)\n",
    "\n",
    "    gnb = GaussianNB()\n",
    "\n",
    "    gnb.fit(data_train, target_train)\n",
    "    print(\"Test set accuracy: {:.2f}\".format(gnb.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is even worse ! The reaseon why this algorithm is so fast but also so bad at generalization is because it learns parameters by looking at each feature individually and collect simple per-class statistics from each feature. Since we have a huge diversity in our dataset, the GaussianNB gives quite bad results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the Bernouilli distribution for different test sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7977, 119)\n",
      "Test set accuracy: 0.72\n",
      "Test set accuracy: 0.70\n",
      "Test set accuracy: 0.71\n",
      "Test set accuracy: 0.70\n",
      "Test set accuracy: 0.73\n",
      "Test set accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "gt = pd.read_csv('../dumps/2020.02.10-12.14.csv')\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data = gt[cols]\n",
    "print(data.shape)\n",
    "target = gt['label']\n",
    "\n",
    "values = [0.1,0.2,0.4,0.6,0.8,0.9]\n",
    "\n",
    "for i in values:\n",
    "    data_train, data_test, target_train, target_test = train_test_split(data,target, test_size = i, random_state = 0)\n",
    "\n",
    "    gnb = BernoulliNB()\n",
    "\n",
    "    gnb.fit(data_train, target_train)\n",
    "    print(\"Test set accuracy: {:.2f}\".format(gnb.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performances are not that bad but one has to know that BernouilliNB is assumes binary data (opposite to the GaussianNB which works for any kind of continuous data). We should therefore perform some tuning and only keep boolean values in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the Multinomial distribution (Note that this distribution only accepts non-negative values, therefore we have to parse our dataset and remove all rows where feature values are below 0) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3771, 119)\n",
      "Test set accuracy: 0.77\n",
      "Test set accuracy: 0.80\n",
      "Test set accuracy: 0.83\n",
      "Test set accuracy: 0.87\n",
      "Test set accuracy: 0.92\n",
      "Test set accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "gt = pd.read_csv('../dumps/2020.02.10-12.14.csv')\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "for col in cols:\n",
    "    gt = gt.drop(gt[gt[col] < 0 ].index)\n",
    "data = gt[cols]\n",
    "print(data.shape)\n",
    "target = gt['label']\n",
    "\n",
    "values = [0.1,0.2,0.4,0.6,0.8,0.9]\n",
    "\n",
    "for i in values:\n",
    "    data_train, data_test, target_train, target_test = train_test_split(data,target, test_size = i, random_state = 0)\n",
    "\n",
    "    gnb = MultinomialNB()\n",
    "\n",
    "    gnb.fit(data_train, target_train)\n",
    "    print(\"Test set accuracy: {:.2f}\".format(gnb.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a dataset reduced by more than 50%, we managed to reach quite acceptable values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion : not suited for our problem of classification between really sparse features except Multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Naive Bayes assumes independence and outputs class probabilities most feature importance criteria are not a direct fit. The feature importance should be no different from the skewness of the feature distribution in the set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with Thomas datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.087\n",
      "Accuracy on test set: 0.086\n",
      "Accuracy on training set: 0.829\n",
      "Accuracy on test set: 0.829\n",
      "Accuracy on training set: 0.248\n",
      "Accuracy on test set: 0.244\n"
     ]
    }
   ],
   "source": [
    "gt = pd.read_csv(\"../dumps/2019-08.Merged_thomas.csv\")\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data = gt[cols]\n",
    "target = gt['label']\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data,target, test_size = 0.20, random_state = 0)\n",
    "\n",
    "tree = GaussianNB()\n",
    "tree.fit(data_train, target_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(data_train, target_train))) \n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(data_test, target_test)))\n",
    "\n",
    "tree = BernoulliNB()\n",
    "tree.fit(data_train, target_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(data_train, target_train))) \n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(data_test, target_test)))\n",
    "\n",
    "for col in cols:\n",
    "    gt = gt.drop(gt[gt[col] < 0 ].index)\n",
    "data = gt[cols]\n",
    "target = gt['label']\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data,target, test_size = 0.20, random_state = 0)\n",
    "\n",
    "tree = MultinomialNB()\n",
    "\n",
    "tree.fit(data_train, target_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(data_train, target_train))) \n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.173\n",
      "Accuracy on test set: 0.172\n",
      "Accuracy on training set: 0.897\n",
      "Accuracy on test set: 0.887\n",
      "Accuracy on training set: 0.223\n",
      "Accuracy on test set: 0.218\n"
     ]
    }
   ],
   "source": [
    "gt = pd.read_csv(\"../dumps/2019-09.Merged_thomas.csv\")\n",
    "cols = [col for col in gt.columns if col not in ['label']]\n",
    "data = gt[cols]\n",
    "target = gt['label']\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data,target, test_size = 0.20, random_state = 0)\n",
    "\n",
    "tree = GaussianNB()\n",
    "tree.fit(data_train, target_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(data_train, target_train))) \n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(data_test, target_test)))\n",
    "\n",
    "tree = BernoulliNB()\n",
    "tree.fit(data_train, target_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(data_train, target_train))) \n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(data_test, target_test)))\n",
    "\n",
    "for col in cols:\n",
    "    gt = gt.drop(gt[gt[col] < 0 ].index)\n",
    "data = gt[cols]\n",
    "target = gt['label']\n",
    "data_train, data_test, target_train, target_test = train_test_split(data,target, test_size = 0.20, random_state = 0)\n",
    "\n",
    "tree = MultinomialNB()\n",
    "tree.fit(data_train, target_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(data_train, target_train))) \n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(data_test, target_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
