\section{Summary} %en vrai on pourrait supprimer ce chapitre je pense

Thanks to the \texttt{scikit-learn} API, we managed to identify which kind of learning was the most suited for our packing classification problem. After that, we identified several potential supervised learning algorithms and understood the way they worked. We then proceeded to a series of experiments in order to find out how data should be preprocessed and parameters tuned according to each classifier. While initial accuracies obtained after this first customisation process were pretty satisfying, other experiences have been conducted via features selection, principal components analysis and time comparison in order to improve the computation time and consolidate the prediction power over new input data. Thereafter, we produced a variety of different datasets following several scenarios in order to identify how the way data are generated impacts, positively or negatively, the resulting accuracies. All this together, each classifier has been run with its best configuration and eventual accuracies have been computed. Based on these, a selection has been established and only the four classifiers offering the best trade-offs between time and accuracy were kept. Finally, a cross-validation as well as an economical analysis were performed to asses their good generalisation power and their stability over time. While all classifiers have shown eloquent results, if we had to keep only one, we would probably go for the Decision Tree model. This is because of its standard deviation of only 0.2\% obtained during economical analysis combined with its training time being faster than its peers.